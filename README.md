# ğŸ“Œ YellowPages Egypt Scraper Dash App
A **fully functional Dash web application** that allows users to **scrape business data** from **YellowPages Egypt** dynamically. The app provides a **real-time UI**, displays scraped data in a table, and allows users to **download the data as a CSV file**.

## ğŸš€ Features
âœ… **User-Friendly Interface**:  
- Simple **Dash web UI** with a **modern design**.  
 

âœ… **Real-Time Scraping Process**:  
- Scrapes **business names, phone numbers, addresses, and websites**.  
- Displays scraped data **dynamically in a table**.  
- **Status Indicator** updates in real-time to show scraping progress.  

âœ… **File Export**:  
- **Download CSV** button to export scraped data instantly.  

âœ… **Optimized Scraper**:  
- Uses **Selenium + BeautifulSoup** for reliable data extraction.  
- **Undetected ChromeDriver** to bypass bot detection by mimicking human like behavior.  
- **Ensures all phone numbers are extracted correctly**.  

## ğŸ“‚ Project Structure
```
ğŸ“ YellowPages-Scraper-Dash
â”‚â”€â”€ app.py              # Main entry point for the Dash app
â”‚â”€â”€ layout.py           # Defines UI layout
â”‚â”€â”€ header.py           # Contains the app header
â”‚â”€â”€ scraper.py          # Handles Selenium-based scraping
â”‚â”€â”€ callbacks.py        # Manages interactivity and callbacks
â”‚â”€â”€ requirements.txt    # List of required dependencies
â”‚â”€â”€ README.md           # Project documentation
```

## ğŸ”§ Installation & Setup
### 1ï¸âƒ£ Install Required Packages
First, **clone the repository** and navigate to the project folder:
```sh
git clone https://github.com/YOUR_GITHUB_USERNAME/YellowPages-Scraper-Dash.git
cd YellowPages-Scraper-Dash
```
Then, install dependencies:
```sh
pip install -r requirements.txt
```

### 2ï¸âƒ£ Install Selenium WebDriver
Make sure **ChromeDriver** is installed and compatible with your browser version. You can download it from:  
ğŸ”— [ChromeDriver Download](https://sites.google.com/chromium.org/driver/)

### 3ï¸âƒ£ Run the App
Start the Dash web app:
```sh
python app.py
```
Then, **open your browser** and go to:
```
http://127.0.0.1:8050/
```

## ğŸ“ How to Use
1ï¸âƒ£ **Enter a keyword** (e.g., "plastic injection") in the input field.  
2ï¸âƒ£ **Click "Start Scraping"** to begin the scraping process.  
3ï¸âƒ£ Watch the **real-time table update** with business details.  
4ï¸âƒ£ **Click "Stop Scraping"** anytime to halt the process.  
5ï¸âƒ£ **Click "Download CSV"** to save the scraped data.

## ğŸ–¼ï¸ Screenshots
| **Main UI** | **Scraping in Progress** |
|------------|--------------------|
| ![UI](screenshot1.png) | ![Scraping](screenshot1.png) |

## ğŸ› ï¸ Technologies Used
- **Python 3.x**
- **Dash (Plotly)**
- **Selenium & BeautifulSoup**
- **Undetected ChromeDriver**
- **Pandas**
- **Flask**

## ğŸ¤ Contributing
Want to improve this project?  
- **Fork** the repo  
- **Create a feature branch** (`git checkout -b new-feature`)  
- **Commit your changes** (`git commit -m "Added a cool feature"`)  
- **Push to the branch** (`git push origin new-feature`)  
- **Open a Pull Request** ğŸ‰  

## ğŸ“œ License
This project is **open-source** under the **MIT License**.

## ğŸ’¬ Contact
For any issues or feature requests, feel free to **open an issue** or reach out via:  
ğŸ“§ Email: **emadsaghier@gmail.com**  
  

### â­ If you like this project, consider giving it a star on GitHub! â­  

ğŸš€ **Happy Scraping!** ğŸ˜Š
